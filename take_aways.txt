
--------------------------------------------------------------------------------------------------------------------------------------
PART 1 : SYSTEM SETUP
--------------------------------------------------------------------------------------------------------------------------------------

-------------------------------------------------------------------
CODESERVER
-------------------------------------------------------------------
> Make a habit of using CodeServer, this can also be used when you are working remotely on servers. It basically gives you a VSCode like environment
> Navigate to the github page from where you can install codeserver, link : https://github.com/cdr/code-server/releases/download/3.2.0/code-server-3.2.0-linux-x86_64.tar.gz
> Run the binary using the following command
PASSWORD=<pass> ./code-server --host 0.0.0.0 --port 10000(any port that you want basically)
-------------------------------------------------------------------

-------------------------------------------------------------------
PROJECT STRUCTURING
-------------------------------------------------------------------
> Now we need to structure the project properly.
---
 |
 |--src/
     |-- train.py
     |-- __init__.py
     |-- metrics.py
     |-- create_folds.py
     |-- predict.py
     |-- dataset.py
     |-- loss.py
     |-- utils.py
     |-- feature_generator.py
     |-- dispatcher.py
     |-- engine.py
 |--input/
 |--models/
 |.git/
 |.gitignore
-------------------------------------------------------------------

-------------------------------------------------------------------
.gitignore
-------------------------------------------------------------------
> Use the standard .gitignore template for python provided by github
	link : https://github.com/github/gitignore/blob/master/Python.gitignore
> We have added additional items based on our project structuring
```
# input data and models
input/
models/

# data files
*.csv
*.h5
*.pkl
*.pth
```
-------------------------------------------------------------------


--------------------------------------------------------------------------------------------------------------------------------------



--------------------------------------------------------------------------------------------------------------------------------------
PART 2 : GATHER DATA AND BUILD CROSS VALIDATION
--------------------------------------------------------------------------------------------------------------------------------------

PS : Right now we are using the categorical feature encoding challenge dataset

-------------------------------------------------------------------
create_folds.py
-------------------------------------------------------------------
> Create K-folds for our problem to perform K-fold cross validation while training
> We will use the sklearn.model_selection.StratifiedKFolds for the same
> We will create a generic script that will do this thing for us
> code is available in src/create_folds.py
-------------------------------------------------------------------


--------------------------------------------------------------------------------------------------------------------------------------
PART 3 : TRAINING A BASIC MODEL
--------------------------------------------------------------------------------------------------------------------------------------

-------------------------------------------------------------------
train.py
-------------------------------------------------------------------
> Now a basic classifier will be trained over this
> Using K_fold validation, therefore it is good to use a k_fold map (check the code)
> train_data and fold to be used can be picked up from an environment variable, so that we can have an abstracted code
> The labels can be label encoded(["yes","no","maybe"] --> [0,1,2]) (Check code to do that)
> use a basic classifier from the sklearn packages (right now random forest)
-------------------------------------------------------------------

-------------------------------------------------------------------

NOTE : ALL THE SCRIPTS ARE RUN USING src.script_name --> this maintains the level at the top of the directory 
> Interesting, I never did this before, so this is how it is going to be from now on
> Structuring machine learning projects from day 1 is a must
-------------------------------------------------------------------


-------------------------------------------------------------------
run.sh
-------------------------------------------------------------------
> To handle the enivronment variables, it is a good idea to have a script to run the python file
> use EXPORT <ENVIRONMENT_VARIABLE> = <VALUE> --> to define environment variables in bash script
-------------------------------------------------------------------


-------------------------------------------------------------------
dispatch.py
-------------------------------------------------------------------
> We can have multiple models that we train, which we can run in the run.sh script and we can comfortably take a break
> This is achieved using this (check dispatch --> map of possible models --> and the subsequent commands)
> We will use this idea from the days ahead, redundancy in the code will be minimal through this
> NOTE in the run.sh --> Take MODEL name using $1 --> first argument in the python -m command
> save the models using joblib (check train.py) --> for each model with proper naming convention
-------------------------------------------------------------------


--------------------------------------------------------------------------------------------------------------------------------------
PART 4 : CROSS VALIDATION FRAMEWORK
--------------------------------------------------------------------------------------------------------------------------------------

Different types of cross validations:
1) KFold
2) Stratified KFold --> Maintains the ratio in the target labels (important in case of class imbalance)
3) Multilabel CLassification
4) Regression cross-validation
5) Hold-out boased validation

